variables:
  AWS_REPOSITORY: $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/my-app

stages:
- cache
- test
- build
- trivy
- deploy

warmup_cache:
  image: node:16
  stage: cache
  script:
  - yarn install
  cache:
    key:
      files:
      - yarn.lock
    paths:
    - node_modules/
    - .yarn
    - yarn.lock
    policy: pull-push
  when: manual

workflow:
  rules:
  - exists:
    - Dockerfile
  test:
   image: node:16
  stage: test
  script:
  - yarn test
  cache:
   key:
    files:
    - yarn.lock
  paths:
  - node_modules/
  - .yarn
  - yarn.lock
  policy: pull
  when: manual

  njsscan:
   stage: test
  image: python
  before_script:
  - pip3 install --upgrade njsscan
  script:
  - njsscan --exit-warning .  --sarif -o njsscan.sarif
  allow_failure: true
  artifacts:
    when: always
    paths:
    - njsscan.sarif
  when: manual

  sast_scan:
   stage: test
   image: returntocorp/semgrep
  variables:
   SEMGREP_RULES: p/javascript
  script: 
  - semgrep ci --json -o semgrep.json
  allow_failure: true
  artifacts:
   when: always
  paths:
  - semgrep.json
  when: manual

  gitLeaks:
   stage: test
   image:
   name: zricethezav/gitleaks
  entrypoint: [""]
  script:
  - gitleaks detect --verbose --source . -f json -r gitleaks.json
  allow_failure: true
  artifacts:
   when: always
  paths:
  - gitleaks.json
  when: manual

  #SCA scanning
  retire:
   stage: test
   image: node:16
   cache:
   key:
    files:
    - yarn.lock
   paths:
   - node_modules/
   - .yarn
   - yarn.lock
   policy: pull
   before_script:
   - npm install -g retire
   script:
   - retire --path . --outputformat json --outputpath retire.json
   allow_failure: true
   artifacts:
   when: always
  paths:
  - retire.json
  when: manual


  upload_reports:
   stage: test
   image: python
  needs: ["gitLeaks", "sast_scan", "njsscan", "retire"]
  when: always
  before_script:
  - pip3 install requests
  script:
  - python3 upload-report.py gitleaks.json
  - python3 upload-report.py njsscan.sarif
  -  python3 upload-report.py semgrep.json
  - python3 upload-report.py retire.json

  # Push image to ECR Repository

build-image:
  stage: build
  image: docker:latest
  services:
  - docker:dind
  when: manual
  variables:
    AWS_ACCESS_KEY_ID: $AWS_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY: $AWS_SECRET_ACCESS_KEY
    AWS_DEFAULT_REGION: $AWS_DEFAULT_REGION
    AWS_ACCOUNT_ID: $AWS_ACCOUNT_ID
  before_script:
  - apk --no-cache add curl python3 py3-pip
  - python3 -m venv /path/to/venv
  - . /path/to/venv/bin/activate
  - pip install awscli
  - aws ecr get-login-password | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
  script:
  - . /path/to/venv/bin/activate
  - aws --version
  - docker build --cache-from $AWS_REPOSITORY:latest -t $AWS_REPOSITORY:$CI_COMMIT_SHA -t $AWS_REPOSITORY:latest .
  - docker push $AWS_REPOSITORY:$CI_COMMIT_SHA
  - docker push $AWS_REPOSITORY:latest

# Scan Docker image
trivy:
 stage: trivy
image: docker:latest
  services:
 - docker:dind
before_script:
- apk --no-cache add curl python3 py3-pip
- python3 -m venv /path/to/venv
- . /path/to/venv/bin/activate
- pip install awscli
- curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin v0.40.0
- aws ecr get-login-password | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
script:
- docker pull $AWS_REPOSITORY:latest
- trivy image -f json -o trivy.json --exit-code 1 --severity HITGH,CRITICAL $AWS_REPOSITORY:latest
allow_failure: true
artifacts:
  when: always
 paths:
 - trivy.json
when: manual




Deploy_App:
  stage: deploy
  image:
    name: amazon/aws-cli
    entrypoint: [ "" ]
  before_script:

  - apt update -y && apt install openssh-client -y
  - eval $(ssh-agent -s)
  - chmod 400 "$SSH_PRIVATE_KEY"
  - ssh-add "$SSH_PRIVATE_KEY"
  - mkdir -p ~/.ssh
  - chmod 700 ~/.ssh

  script:
  - LOG_IN_CMD="export AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION; export AWS_ACCOUNT_ID=$AWS_ACCOUNT_ID; aws ecr get-login-password | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com"
  - COMMAND_TO_EXECUTE="docker pull $AWS_REPOSITORY:latest && (docker stop juice-shop || true) && (docker rm juice-shop || true) && docker run -d -p 3000:3000  --name juice-shop $AWS_REPOSITORY:latest"
  - COMMAND_ID=$(aws ssm send-command --instance-ids "i-01a8a362652d0cb15" --document-name "AWS-RunShellScript" --parameters "commands=[$LOG_IN_CMD, $COMMAND_TO_EXECUTE]" --query "Command.CommandId" --output text)
  #- aws ssm wait command-executed --command-id "$COMMAND_ID" --instance-id "i-01a8a362652d0cb15"
  - sleep 15
  - aws ssm get-command-invocation --command-id "$COMMAND_ID" --instance-id "i-01a8a362652d0cb15"
  - ssh -o StrictHostKeyChecking=no ubuntu@54.236.28.227 "docker pull $AWS_REPOSITORY:latest"
  - ssh -o StrictHostKeyChecking=no ubuntu@54.236.28.227 "docker stop juice-shop || true"
  - ssh -o StrictHostKeyChecking=no ubuntu@54.236.28.227 "docker rm juice-shop || true"
  - ssh -o StrictHostKeyChecking=no ubuntu@54.236.28.227 "docker run -d -p 3000:3000  --name juice-shop $AWS_REPOSITORY:latest"
  when: manual

dast_testing:
  stage: deploy
  needs: [ "Deploy_App" ]
  image: ghcr.io/zaproxy/zaproxy:stable
  before_script:
  - mkdir -p /zap/wrk
  script:
  - zap-baseline.py -t "http://52.90.236.46:3000" -g gen_file -I -x testreport.xml
  - cp /zap/wrk/testreport.xml testreport.xml
  artifacts:
    paths:
    - testreport.xml
  when: manual
